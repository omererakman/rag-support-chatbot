# RAG Support Chatbot

A production-ready Retrieval-Augmented Generation (RAG) support chatbot built with LangChain, TypeScript, and modern best practices. This system enables intelligent question-answering over your support documentation with comprehensive error handling, observability, security, and performance optimizations.

## ğŸš€ Features

### Core Capabilities
- **Modern LangChain Architecture** - Built with LangChain, type-safe chains
- **Multiple Retrieval Strategies** - Similarity search, MMR (Maximum Marginal Relevance), and Contextual Compression
- **Flexible Vector Stores** - ChromaDB or memory store with disk persistence
- **Type-Safe** - Full TypeScript with Zod schema validation throughout
- **Structured Responses** - Rich JSON responses with source citations, metadata, safety information, and confidence scores
- **Answer Confidence Scoring** - Multi-factor confidence scoring to assess answer reliability

### Production-Ready Features
- **Resilience** - Automatic retry with exponential backoff, circuit breakers, and timeout handling
- **Error Handling** - Custom error types with proper error propagation and recovery
- **Performance** - Caching infrastructure (for future use when transitioning from single-run scripts to persistent applications), connection pooling, and batch optimizations
- **Observability** - Structured logging (JSON/text), metrics collection, distributed tracing, and LangChain callbacks
- **Security** - Input sanitization, PII detection/redaction, content moderation, and prompt injection detection

### Safety & Security
- **Content Moderation** - OpenAI moderation API integration
- **PII Detection** - Automatic detection and redaction of personally identifiable information
- **Prompt Injection Protection** - Pattern-based detection of injection attempts
- **Input Sanitization** - Removes dangerous characters and patterns

## ğŸ“‹ Prerequisites

- **Node.js** 22+
- **npm**
- **Windows users** - Git Bash is recommended for Windows users to run bash commands seamlessly
- **OpenAI API Key** - Required for LLM and embeddings
- **Vector Store** - Choose one:
  - **ChromaDB** (suggested) - See setup instructions below
  - **Memory** (alternative) - No additional setup required, uses in-memory store with disk persistence

### ChromaDB Setup

ChromaDB is the recommended vector store. You can set it up using Docker Compose or Docker directly:

**Using Docker Compose (recommended):**
```bash
# Start ChromaDB using Docker Compose
docker-compose up -d

# Or start in foreground to see logs
docker-compose up

# Stop ChromaDB
docker-compose down

# Stop and remove volumes (clears all data)
docker-compose down -v
```

The `docker-compose.yml` file includes:
- Persistent data storage
- Health checks for monitoring
- Automatic restart on failure
- Port mapping (8000:8000)

**Alternative: Using Docker directly**
```bash
docker run -p 8000:8000 chromadb/chroma
```

Then configure in `.env`:
```env
VECTOR_STORE_TYPE=chromadb
CHROMA_HOST=localhost
CHROMA_PORT=8000
```

**Note:** If you prefer to use the memory vector store instead, set `VECTOR_STORE_TYPE=memory` in your `.env` file. The memory store persists data to disk in `storage/memory-vector-store.json` for later query usage.

## ğŸ› ï¸ Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd rag-support-chatbot
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Configure environment variables:**
   ```bash
   cp .env.example .env
   ```

4. **Edit `.env` with your configuration:**
   ```env
   OPENAI_API_KEY=your-api-key-here
   LLM_MODEL=gpt-4o-mini
   EMBEDDING_MODEL=text-embedding-3-small
   VECTOR_STORE_TYPE=chromadb  # or 'memory'
   ```

## ğŸ¯ Quick Start

### 1. Prepare Your Documents

Place your support documentation in the `data/` directory. Supported formats include:
- Plain text files (`.txt`)
- Markdown files (`.md`)
- Other text-based formats

Example:
```bash
data/
â”œâ”€â”€ faq_document.txt
â”œâ”€â”€ any other text documents...
```

### 2. Build the Vector Index

Build the vector index from your documents:

```bash
npm run dev
```

The script defaults to the `./data` directory. To use a custom path:

```bash
npm run dev -- ./path/to/your/documents
```

The script will:
- Load all documents from the specified directory (defaults to `./data`)
- Split them into chunks with configurable size and overlap
- Generate embeddings using OpenAI
- Store embeddings in your configured vector store
  - **ChromaDB**: Stores embeddings in the ChromaDB database
  - **Memory**: Stores embeddings in memory and persists to `storage/memory-vector-store.json` for later query usage

### 3. Query the System

Ask questions using the query script:

```bash
npm run dev:query -- "What is your return policy?"
```

### Example Response

The response includes metadata about the search process, timing information, token usage, cache information (for future use), safety checks, and confidence scoring:

```json
{
  "user_question": "What is your return policy?",
  "system_answer": "We offer a 30-day money-back guarantee for new subscriptions. If you're not satisfied within the first 30 days, you can contact our support team with your order number and reason for the refund request. Refunds are processed within 5-7 business days and will appear on your original payment method. After 30 days, refunds are not available, but you can cancel your subscription at any time.",
  "chunks_related": [
    {
      "id": "chunk-0",
      "text": "What is your refund policy?\nWe offer a 30-day money-back guarantee for new subscriptions. If you're not satisfied with our service within the first 30 days, contact our support team with your order number and reason for the refund request. Refunds are processed within 5-7 business days and will appear on your original payment method. After 30 days, refunds are not available, but you can cancel your subscription at any time. Cancelled subscriptions remain active until the end of the current billing period.",
      "index": 0,
      "startChar": 4183,
      "endChar": 4693,
      "sourceId": "/data/faq_document.txt",
      "metadata": {
        "loc": {
          "lines": {
            "from": 36,
            "to": 37
          }
        },
        "similarityScore": 0.9410361,
        "score": 0.9410361
      }
    },
    {
      "id": "chunk-1",
      "text": "What happens to data when I cancel my subscription?\nWhen you cancel your subscription, your account enters a grace period during which you can export all your data. After the grace period, your account is deactivated, but data is retained for 90 days in case you want to reactivate. After 90 days, data is permanently deleted according to our data retention policy. You can request immediate data deletion if needed.\n\nDOCUMENT MANAGEMENT",
      "index": 1,
      "startChar": 39012,
      "endChar": 39449,
      "sourceId": "/data/faq_document.txt",
      "metadata": {
        "loc": {
          "lines": {
            "from": 292,
            "to": 295
          }
        },
        "similarityScore": 1.3861737,
        "score": 1.3861737
      }
    },
    {
      "id": "chunk-2",
      "text": "What data backup and recovery procedures are in place?\nWe perform automated daily backups of all data, with backups retained for 90 days. Data is stored in multiple geographically distributed data centers for redundancy. In the event of data loss, we can restore data from backups. Recovery time objectives (RTO) and recovery point objectives (RPO) are documented in our SLA. Enterprise customers can request custom backup and retention policies.",
      "index": 2,
      "startChar": 38157,
      "endChar": 38603,
      "sourceId": "/data/faq_document.txt",
      "metadata": {
        "loc": {
          "lines": {
            "from": 286,
            "to": 287
          }
        },
        "similarityScore": 1.4441562,
        "score": 1.4441562
      }
    },
    {
      "id": "chunk-3",
      "text": "What happens if my payment fails?\nIf a payment fails, we'll send you an email notification and attempt to charge your card again after 3 days. You'll have a 7-day grace period to update your payment method. During this time, your account will remain active. If payment is not resolved after 7 days, your account will be suspended, and you'll lose access to all features. To reactivate, simply update your payment method and the account will be restored immediately.",
      "index": 3,
      "startChar": 5107,
      "endChar": 5572,
      "sourceId": "/data/faq_document.txt",
      "metadata": {
        "loc": {
          "lines": {
            "from": 42,
            "to": 43
          }
        },
        "similarityScore": 1.4567606,
        "score": 1.4567606
      }
    },
    {
      "id": "chunk-4",
      "text": "SUPPORT AND HELP\n\nWhat are your business hours?\nOur customer support team is available Monday through Friday, 9 AM to 6 PM Eastern Time. We also offer limited support on weekends from 10 AM to 4 PM Eastern Time. Enterprise customers have access to 24/7 priority support via phone, email, or live chat. For urgent issues outside business hours, Enterprise customers can use our emergency support line. Response times vary by plan: Starter (24-48 hours), Professional (4-8 hours), Enterprise (1-2 hours).",
      "index": 4,
      "startChar": 48398,
      "endChar": 48900,
      "sourceId": "/data/faq_document.txt",
      "metadata": {
        "loc": {
          "lines": {
            "from": 371,
            "to": 374
          }
        },
        "similarityScore": 1.4802177,
        "score": 1.4802177
      }
    }
  ],
  "metadata": {
    "searchMethod": "similarity",
    "topK": 5,
    "model": "gpt-4o-mini",
    "searchTimeMs": 478,
    "tokenUsage": {
      "promptTokens": 554,
      "completionTokens": 81,
      "totalTokens": 635
    },
    "timings": {
      "safetyCheckMs": 490,
      "retrievalMs": 478,
      "llmGenerationMs": 2556,
      "totalMs": 3525
    },
    "cache": {
      "retrievalHit": false,
      "llmHit": false
    },
    "confidence": {
      "score": 0.995872527,
      "level": "high",
      "factors": {
        "retrieval": 0.9882072199999999,
        "relevance": 1,
        "coverage": 1,
        "answerQuality": 1
      },
      "explanation": "highly relevant documents"
    }
  },
  "safety": {
    "safe": true,
    "moderationFlagged": false,
    "injectionDetected": false,
    "piiDetected": false,
    "flaggedCategories": []
  }
}
```

### Sample Queries

The `outputs/sample_queries.json` file contains example query responses demonstrating various scenarios:
- Successful queries with full responses, metadata, and confidence scores
- Error cases showing safety checks (e.g., PII detection and redaction)

## âš™ï¸ Configuration

All configuration is done via environment variables. See `.env.example` for all available options.

### Provider Configuration

```env
# LLM Provider (currently supports: openai)
LLM_PROVIDER=openai
LLM_MODEL=gpt-4o-mini

# Embedding Provider (currently supports: openai)
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small

# OpenAI Configuration
OPENAI_API_KEY=your-api-key-here
```

### Chunking Configuration

```env
CHUNK_SIZE=800              # Characters per chunk
CHUNK_OVERLAP=100           # Overlap between chunks
MIN_CHUNKS=20               # Minimum chunks required for index building
```

### Vector Store Configuration

```env
# Options: 'chromadb' or 'memory'
VECTOR_STORE_TYPE=chromadb

# ChromaDB Configuration (only if using chromadb)
CHROMA_COLLECTION_NAME=support_embeddings
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_SSL=false             # Enable SSL for ChromaDB connection (default: false)
CHROMA_API_KEY=              # Optional, for authenticated ChromaDB instances
```

**Note on Memory Vector Store**: When using `VECTOR_STORE_TYPE=memory`, the vector store persists data to disk in `storage/memory-vector-store.json`. This allows the index built by the indexing script to be available for queries in separate script runs. The data is automatically saved when building the index and automatically loaded when querying.

### Retrieval Configuration

```env
# Options: 'similarity', 'mmr', or 'compression'
RETRIEVER_TYPE=similarity

TOP_K=5                      # Number of documents to retrieve
SCORE_THRESHOLD=0.5          # Minimum similarity score (0-1)

# Reranking (optional)
RERANK_ENABLED=false
RERANK_TOP_N=20             # Documents to rerank
RERANK_TOP_K=5              # Final documents after reranking
```

### Safety Configuration

```env
SAFETY_ENABLED=true          # Enable/disable all safety checks
```

### Confidence Scoring Configuration

```env
CONFIDENCE_ENABLED=true                    # Enable/disable confidence scoring (default: true)
CONFIDENCE_LOW_THRESHOLD=0.4              # Threshold for low confidence (0-1)
CONFIDENCE_MEDIUM_THRESHOLD=0.6            # Threshold for medium confidence (0-1)
CONFIDENCE_HIGH_THRESHOLD=0.8              # Threshold for high confidence (0-1)
CONFIDENCE_INCLUDE_FACTORS=true            # Include factor breakdown in response (default: true)
```

**Confidence Levels:**
- **High** (â‰¥0.8): Highly reliable answer based on relevant documents
- **Medium** (0.6-0.8): Moderately reliable answer
- **Low** (0.4-0.6): Low confidence, answer may be incomplete or uncertain
- **Very Low** (<0.4): Very low confidence, answer may be unreliable

**Confidence Factors:**
- **Retrieval** (35%): Average similarity score of retrieved documents
- **Relevance** (30%): Top document similarity score
- **Coverage** (15%): Document count relative to expected
- **Answer Quality** (20%): Answer length and uncertainty phrase detection

### Cache Configuration

**Note**: The caching module is implemented but reserved for future use. Currently, the application runs as single-run scripts (indexing and querying), where in-memory caching provides no benefit since each script execution starts fresh. Caching will become useful when the application transitions to a persistent application (e.g., a web server or long-running service) where multiple requests can benefit from cached results, or when using a persistent cache provider (e.g., Redis, Memcached) that maintains cache state across script executions.

```env
CACHE_ENABLED=false          # Enable/disable caching (default: false)
CACHE_TTL=3600               # Cache TTL in seconds (default: 3600 = 1 hour)
CACHE_EMBEDDINGS=false       # Cache embedding results (default: false)
CACHE_RETRIEVAL=false        # Cache retrieval results (default: false)
CACHE_LLM=false              # Cache LLM responses (default: false)
```

### Logging Configuration

```env
LOG_LEVEL=info               # Options: debug, info, warn, error
LOG_FORMAT=auto              # Options: json, text, auto (auto uses text in dev, json in prod)
NODE_ENV=development         # Options: development, production, test
```

## ğŸ—ï¸ Architecture

> ğŸ“– **For detailed architectural decisions and design rationale, see [ARCHITECTURE.md](./ARCHITECTURE.md)**

The system uses LangChain's LCEL (LangChain Expression Language) for composable chain construction:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Question  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Safety Check    â”‚ â—„â”€â”€ Moderation, PII Detection, Injection Detection
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Retrieval     â”‚ â—„â”€â”€ Vector Store Search (Similarity/MMR/Compression)
â”‚  (with scores)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Generation    â”‚ â—„â”€â”€ LLM with Retrieved Context
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Confidence     â”‚ â—„â”€â”€ Multi-Factor Confidence Scoring
â”‚   Calculation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Structured     â”‚
â”‚    Response     â”‚ â—„â”€â”€ Includes confidence metadata
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

- **Safety Chain** - Validates input for moderation, PII, and injection attempts
- **Retrievers** - Multiple retrieval strategies with configurable parameters (extracts similarity scores)
- **Vector Stores** - Pluggable vector store implementations
- **LLM Chain** - Configurable LLM providers with prompt templates
- **Confidence Scoring** - Multi-factor confidence calculation based on retrieval quality, relevance, coverage, and answer quality
- **Monitoring** - Metrics, tracing, and logging throughout the pipeline

### Resilience Features

- **Retry Logic** - Exponential backoff for transient failures
- **Circuit Breakers** - Prevents cascading failures
- **Timeouts** - Prevents hanging operations
- **Error Types** - Custom error types for different failure scenarios

## ğŸ“ Project Structure

```
rag-support-chatbot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts                    # Build index entry point
â”‚   â”œâ”€â”€ query.ts                    # Query pipeline entry point
â”‚   â”œâ”€â”€ logger.ts                   # Logging configuration
â”‚   â”œâ”€â”€ config/                     # Configuration management
â”‚   â”‚   â”œâ”€â”€ env.ts                  # Environment variable loading
â”‚   â”‚   â”œâ”€â”€ validation.ts           # Config validation
â”‚   â”‚   â””â”€â”€ index.ts                # Config exports
â”‚   â”œâ”€â”€ chains/                     # LangChain chains (LCEL)
â”‚   â”‚   â””â”€â”€ rag-chain.ts            # Main RAG chain
â”‚   â”œâ”€â”€ loaders/                    # Document loaders
â”‚   â”‚   â””â”€â”€ directory-loader.ts     # Directory-based loading (supports .txt and .md files)
â”‚   â”œâ”€â”€ splitters/                  # Text splitting
â”‚   â”‚   â””â”€â”€ index.ts                # Text splitter factory (RecursiveCharacterTextSplitter)
â”‚   â”œâ”€â”€ embeddings/                 # Embedding providers
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â””â”€â”€ openai.ts           # OpenAI embeddings
â”‚   â”‚   â””â”€â”€ index.ts                # Embedding factory
â”‚   â”œâ”€â”€ vector-stores/              # Vector store implementations
â”‚   â”‚   â”œâ”€â”€ chroma.ts               # ChromaDB implementation
â”‚   â”‚   â”œâ”€â”€ memory.ts               # In-memory implementation with disk persistence
â”‚   â”‚   â”œâ”€â”€ memory-vector-store.ts  # Persistence layer for memory vector store
â”‚   â”‚   â”œâ”€â”€ health.ts               # Health checks
â”‚   â”‚   â””â”€â”€ index.ts                # Vector store factory
â”‚   â”œâ”€â”€ retrievers/                 # Retriever implementations
â”‚   â”‚   â”œâ”€â”€ similarity.ts           # Similarity search
â”‚   â”‚   â”œâ”€â”€ mmr.ts                  # Maximum Marginal Relevance
â”‚   â”‚   â”œâ”€â”€ compression.ts          # Contextual Compression
â”‚   â”‚   â””â”€â”€ index.ts                # Retriever factory
â”‚   â”œâ”€â”€ safety/                     # Safety checks
â”‚   â”‚   â”œâ”€â”€ moderation.ts           # Content moderation
â”‚   â”‚   â”œâ”€â”€ pii.ts                  # PII detection/redaction
â”‚   â”‚   â”œâ”€â”€ injection.ts            # Prompt injection detection
â”‚   â”‚   â””â”€â”€ index.ts                # Safety chain
â”‚   â”œâ”€â”€ llm/                        # LLM providers
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â””â”€â”€ openai.ts           # OpenAI LLM
â”‚   â”‚   â””â”€â”€ index.ts                # LLM factory
â”‚   â”œâ”€â”€ prompts/                    # Prompt templates
â”‚   â”‚   â””â”€â”€ rag.ts                  # RAG prompt template
â”‚   â”œâ”€â”€ utils/                      # Utilities
â”‚   â”‚   â”œâ”€â”€ errors.ts               # Custom error types
â”‚   â”‚   â”œâ”€â”€ retry.ts                # Retry logic
â”‚   â”‚   â”œâ”€â”€ timeout.ts              # Timeout handling
â”‚   â”‚   â”œâ”€â”€ circuit-breaker.ts      # Circuit breaker pattern
â”‚   â”‚   â”œâ”€â”€ token-counter.ts        # Token counting
â”‚   â”‚   â””â”€â”€ validation.ts           # Validation utilities
â”‚   â”œâ”€â”€ monitoring/                 # Observability
â”‚   â”‚   â”œâ”€â”€ metrics.ts              # Metrics collection
â”‚   â”‚   â”œâ”€â”€ tracing.ts              # Distributed tracing
â”‚   â”‚   â””â”€â”€ callbacks.ts            # LangChain callbacks
â”‚   â”œâ”€â”€ cache/                      # Caching layer
â”‚   â”‚   â”œâ”€â”€ memory-cache.ts         # In-memory cache implementation
â”‚   â”‚   â”œâ”€â”€ factory.ts              # Cache factory and configuration
â”‚   â”‚   â”œâ”€â”€ utils.ts                # Cache utilities (hashing, safe operations)
â”‚   â”‚   â””â”€â”€ index.ts                # Cache exports
â”‚   â”œâ”€â”€ security/                   # Security utilities
â”‚   â”‚   â””â”€â”€ sanitization.ts         # Input sanitization
â”‚   â””â”€â”€ types/                      # TypeScript types
â”‚       â”œâ”€â”€ schemas.ts              # Zod schemas
â”‚       â””â”€â”€ index.ts                # Type exports
â”œâ”€â”€ data/                           # Source documents (example)
â”‚   â””â”€â”€ faq_document.txt
â”œâ”€â”€ outputs/                        # Output files
â”‚   â””â”€â”€ sample_queries.json         # Example query responses
â”œâ”€â”€ storage/                        # Runtime data storage (gitignored)
â”‚   â””â”€â”€ memory-vector-store.json    # Persisted memory vector store data (created at runtime)
â”œâ”€â”€ tests/                          # Test suite
â”‚   â”œâ”€â”€ unit/                       # Unit tests
â”‚   â”œâ”€â”€ integration/                # Integration tests
â”‚   â”œâ”€â”€ e2e/                        # End-to-end tests
â”‚   â””â”€â”€ utils/                      # Test utilities
â”œâ”€â”€ dist/                           # Compiled output (generated)
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ vitest.config.ts
â””â”€â”€ eslint.config.js
```

## ğŸ§ª Development

### Build

Compile TypeScript to JavaScript:

```bash
npm run build
```

### Type Checking

Check types without building:

```bash
npm run typecheck
```

### Linting

Run ESLint:

```bash
npm run lint
```

### Formatting

Format code with Prettier:

```bash
npm run format
```

### Testing

Run the test suite:

```bash
npm test
```

Run tests in watch mode:

```bash
npm run test:watch
```

Run tests with coverage:

```bash
npm run test:coverage
```

## ğŸš¢ Production Deployment

### Prerequisites

1. Set `NODE_ENV=production` in your environment
2. Use ChromaDB for vector storage (`VECTOR_STORE_TYPE=chromadb`)
3. Configure proper logging level (`LOG_LEVEL=info` or `warn`)
4. Ensure all required environment variables are set

### Build for Production

```bash
npm run build
```

### Running in Production

The compiled JavaScript will be in the `dist/` directory. Use a process manager like PM2 or systemd:

**With Node directly:**
```bash
node dist/src/index.js ./data
```


## ğŸ“Š Observability

### Logging

The system uses structured logging with Pino:

- **Development**: Human-readable text logs
- **Production**: JSON logs for log aggregation systems
- **Correlation IDs**: Each request gets a unique correlation ID for tracing

### Metrics

Metrics are collected for:
- Operation counts (queries, retrievals, generations)
- Error rates
- Operation timings
- Token usage (prompt, completion, total)

Metrics are logged via structured logging and can be accessed programmatically through the `MetricsCollector` singleton.

### Tracing

Distributed tracing is available for:
- Safety checks
- Retrieval operations
- LLM generation
- End-to-end query processing

## ğŸ”’ Security Features

### Content Moderation
- Uses OpenAI's moderation API to detect harmful content
- Blocks queries containing flagged categories

### PII Detection
- Detects personally identifiable information (emails, phone numbers, SSNs, etc.)
- Automatically redacts PII from queries before processing
- Logs PII detection events

### Prompt Injection Protection
- Pattern-based detection of injection attempts
- Blocks common injection patterns

### Input Sanitization
- Removes dangerous characters and patterns
- Prevents XSS and other injection attacks

## ğŸ› Error Handling

The system includes comprehensive error handling:

- **Custom Error Types** - Specific error types for different scenarios
- **Retry Logic** - Automatic retry with exponential backoff for transient failures
- **Circuit Breakers** - Prevents cascading failures when services are down
- **Timeouts** - Prevents hanging operations
- **Error Propagation** - Proper error propagation with context

## ğŸš€ Future Enhancements

- **Handle LLM Context Window** - Prevent and manage context window overflow
- **Distributed Caching** - Support for persistent cache providers (Redis, Memcached)
- **Web Server/API** - Transition from single-run scripts to a persistent web server or API service


## ğŸ“ License

MIT
